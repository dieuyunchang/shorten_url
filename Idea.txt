Dear interviewer! Good day.
Thanks for taking your time to review my test.
I write this document to explain the idea and also share my opinion to able adapting real life situations.
Because the test doesn't require to build the UI for user authentication, so I decided to build only UI for login page that help for checking, but the API for sign up and log out are ready, 
please read the README.md file for more information.

1/ The idea of encode and decode service
  a/ current
    - Because the requirement is required `URL can be encoded into a short URL and that the short URL can be decoded back into the original URL`, so I decided to use the the record id 
    to encode and decode back id to get the original_url.
    - The Encode idea is try to get the remainder of division a by alphabet string length, with alphabet is the character from 0-9,a-z,A-Z, uniq character.
    - The result of Encode service will be the short_code with length from 1-6
    - Flow
      - User submit the long url from UI
      - `Api::ShortenController`(app/controllers/api/shorten_controller.rb) call the service `CreateShortenLink`(app/services/create_shorten_link.rb)
      - The service `CreateShortenLink` will check the `ShortenedUrl` table to find the existing one by sanitize the original url
        - if have, Encode the found record id and return the shortened link
        - if don't have, then create the `ShortenedUrl` record and encode the `shortened_url.id` and return the shortened link
      - `Api::ShortenController` respond the shortened link
      - Guest user input this shortened link into browser
      - LinkController will call the finder `OriginalUrlFinder` with short_code
      - The finder will decode the short_code to get the id and find `ShortenedUrl` to get the original_url
      - LinkController redirect to original_url if found, or redirect to 404 page

    - The limitation of this way are:
      - the short_code can be more then 7 character if the id more than ~ 5.000.000 (5mil)
      - each character of short_code can't be repeated, that mean it reduce the value can be assigned
    - The good one:
      - because the character will be generated by increment id, so no conflict on generate the short_code
      - we don't need to store the short_code
  b/ real life
    - Can create the short_code by the original_url with:
      - Digest::SHA256.hexdigest(original_url)[0..5]
      - Or can random with SecureRandom.hex(10)[0..5]
      - This way will have the conflict case with the generated short_code can be existed in `ShortenedUrl` table, then we need to use while(loop) to generate a uniq short_code
    - Store the short_code into the `ShortenedUrl` attribute, then we can find the original_url by this short_code instead

2/ The idea of rate limit request
  a/ current
    - because the requirement have a bit confusing about the service will serve continuously for a few numbers of users (max 2 - 5 requests per second), I don't know that should stop and not allow
    user to call api or should allow them via pushing into queue
    - So I implement with block the request when server full, response with status 503 with the gem "rack-attach"

  b/ In a scenario that requirement is allow user still able to send the request. The idea for implementation can be:
    - Add sidekiq gem to use the background job
    - Each request will be push into the queue
    - When reaching the limit rate, we can set the waiting time for the job, the counting rate can store in redis:
      - request come -> create the background job
      - plus 1 into the counter
      - when the job finish, counter minus 1
    - The best case
      - may not have a server busy message show up to end user
    - The worst case
      - End user may receive the time out message
      - End user don't know when the job will be finished
      - Server needs to deal with queue congestion

  c/ real life
    My opinion is we should block the request and let user retry again
    - The good point:
      - To avoid the conflict happen at the same time when have a lot of request access
      - Avoid DDOS
      - Better user experience when don't need to wait and don't know when it done, or when they can re-try

    - The worst case
      - The user will see the server busy message.
      - The revenue may be affected if the business is based on the total successful request.

3/ life of records
  - For the long term, the data will be fat and almost shortened_url are used after a while. So I would like to recommend that we should have the expired date for each shortened_url record and have the scheduler to 
  clean up it after 7 days or 1 months...
  - This action will help to control the fating of data stored, also to avoid the while loop to find existing short_code on generator because we can use the deleted one.

4/ Auto Scaling and load balancer
  - I don't have the experience on setting up this one, but when adapting to real life situations, when receiving a lot requests access in the short time, then we may need to think about the upgrade server 
  to handle large access.
  - Auto scaling and load balancer will be the best help on this situation, we can make the server scale up or down by matching traffic. You can decided the which kind of scaling, horizontal with adding more
  server/machine, vertical scaling with increasing the RAM memory or the server power. Load balancer can help to void the overload of each server.
  - It also helps to reduce or balance the cost.


An great idea from the Oivan leader: Cáº£nh
Because we still need to check the existing value in the database, so to void it we can store all the short_code into one table and get it one by one for each request.
We can delete the record when it used and create back when destroy the shorten_url record
We will have 6^62 with 6 is character length, 62 is the alphabet character that can be assigned
`Encode::ALPHABET.length`
The solution is till have limit because the request can more than 6^62, so we can have more column for country ip, or can use sub domain,..

